<hr/>
<h3>Introduction to DSSG - July 05, 2014</h3>
<hr/>
<p>
I'm spending this summer as a fellow at the
<%= link_to "Data Science for Social Good", "http://dssg.io" %>
summer fellowship through the University of Chicago Urban Center for
Computation and Data. We've been at it for just over a month now, and now seems
like a good time to summarize some of my thoughts. I'll do a brief overview of
the program and then move into the nitty gritty learnings.
</p>
<p>
The staff at DSSG (@rayidghani, @mattgee, ...) have done
an excellent job both of rounding up non-profits with interesting datasets and
of finding data scientists to work with them. The twelve projects were selected
from a large pool of possibilities for three qualities in particular: the
significance of the problems they posed, the quality of their datasets, and the
likelihood that an effective solution to their problem could be found using the
techniques available to data science.
</p>
<p>
Consistent with the primary purpose of the program, fellows were chosen as much
for their desire to do social good as they were for their ability to execute.
We're here to solve tough, meaningful problems with real-world, messy data.
To achieve that, each project is staffed by four fellows with particular
interest in or expertise in some aspect of the data science, like natural
language processing or a particular type of machine learning.
</p>
<p>
But the program has another extremely important purpose which doesn't get
quite as much of the limelight as the "do social good" part does: they also
want to teach us how to be good data scientists. Among us are students of
statistics, public policy, design, math, computer science, and engineering.
(There are also some weirdos that have degrees like Chemistry.) We have an
awful lot of different strengths and abilities. With access to such a breadth
and depth of expertise, it would be a shame if we learned nothing from each
other. Thankfully, the staff have done a good job of setting up structural
support for a shared learning experience, with fellow-led "learning lunches"
and other education-driven break-out sessions.
</p>
<p>
On the whole, I've been impressed by the pattern of introspection I've seen
among the fellows and the staff. I also find it unsurprising that with twelve
teams operating in parallel on these problems and sharing resources, some
common challenges have begun to emerge. One of my main personal goals for
the fellowship has been to discover which problems plague data scientists and
to distill the essence of how to handle them.
</p>
<p>
These are some of the main problems I've observed and encountered:
</p>
<p>
<ul>
  <li>The data doesn't match the problem. (Also: There's too little data.)
  <ul>
    <li>More accurately: data is related but not predictive.</li>
    <li>Not enough of the right kind of data.</li>
  </ul>
  </li>
  <li>The data is messy.
  <ul>
    <li>Inconsistent labeling.</li>
    <li>Comes from multiple sources.</li>
    <li>Missing.</li>
    <li>Inaccurate.</li>
    <li>Misleading.</li>
  </ul>
  </li>
  <li>There's too much data.
  <ul>
    <li>Doesn't fit in memory.</li>
    <li>Difficult to decide how to subsample it.</li>
  </ul>
  </li>
  <li>There are privacy restrictions on the data.
  <ul>
    <li>Corporations don't want their trade secrets made public.</li>
    <li>Individuals don't want personal information made public.</li>
  </ul>
  </li>
</ul>
</p>
<p>
Most of the data problems seem to fall into one of categories above. This is
just my best guess, though, and I'll do a bit of digging to see if
people agree.
</p>
<p>
Each of these problems deserves more attention than this, but here they are.
I'll try to keep adding to the list as I see more patterns emerging.
</p>
<br/>
<br/>
